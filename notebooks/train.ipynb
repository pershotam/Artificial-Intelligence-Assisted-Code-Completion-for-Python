{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_5CfLuGpQZG"
   },
   "source": [
    "[![Github](https://img.shields.io/github/stars/lab-ml/python_autocomplete?style=social)](https://github.com/lab-ml/python_autocomplete)\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lab-ml/python_autocomplete/blob/master/notebooks/train.ipynb)\n",
    "\n",
    "# Train a character level autoregressive model on Python source code\n",
    "\n",
    "This notebook will download repositories linked from [Awesome PyTorch List](https://github.com/bharathgs/Awesome-pytorch-list/) and train a character level model.\n",
    "\n",
    "[Evaluation notebook](https://github.com/lab-ml/python_autocomplete/blob/master/notebooks/evaluate.ipynb) evaluates the trained model on some samples. [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lab-ml/python_autocomplete/blob/master/notebooks/evaluate.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mqZ9rxa9pQZN"
   },
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_TGiFpndux7n"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install labml labml_python_autocomplete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pRyp_81TpQZP"
   },
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "A45AlnGKvWxQ"
   },
   "outputs": [],
   "source": [
    "from python_autocomplete import create_dataset\n",
    "from labml.logger import inspect\n",
    "from labml import monit, lab\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aiyH6ebkpQZP"
   },
   "source": [
    "## Prepare dataset\n",
    "\n",
    "We will step-by-step\n",
    "\n",
    "1. download `readme` file from Awesome PyTorch List\n",
    "2. pick github links in it\n",
    "3. download those repositories\n",
    "4. remove non python files\n",
    "5. merge all python files into a training/validation text\n",
    "\n",
    "The code for this is in [`create_dataset.py`](https://github.com/lab-ml/python_autocomplete/blob/master/python_autocomplete/create_dataset.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "fJHF_qsvu5zz"
   },
   "outputs": [],
   "source": [
    "create_dataset.create_folders()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4LKEDKTI-Fes"
   },
   "source": [
    "Get the list of repositories from [Awesome-PyTorch-list](https://github.com/bharathgs/Awesome-pytorch-list/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "9WqEth0cOD8e",
    "outputId": "c70c4221-858a-4ceb-941d-7f169b26e93f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"overflow-x: scroll;\"><span style=\"color: #60C6C8\">  0: </span><strong>('pytorch', 'text')</strong>\n",
       "<span style=\"color: #60C6C8\">  1: </span><strong>('IBM', 'pytorch-seq2seq')</strong>\n",
       "<span style=\"color: #60C6C8\">  2: </span><strong>('Sandeep42', 'anuvada')</strong>\n",
       "<span style=\"color: #60C6C8\">  3: </span><strong>('pytorch', 'audio')</strong>\n",
       "<span style=\"color: #60C6C8\">  4: </span><strong>('facebookresearch', 'loop')</strong>\n",
       "<span style=\"color: #60C6C8\">  5: </span><strong>('facebookresearch', 'fairseq-py')</strong>\n",
       "<span style=\"color: #60C6C8\">  6: </span><strong>('awni', 'speech')</strong>\n",
       "<span style=\"color: #60C6C8\">  7: </span><strong>('OpenNMT', 'OpenNMT-py')</strong>\n",
       "<span style=\"color: #60C6C8\">  8: </span><strong>('huggingface', 'neuralcoref')</strong>\n",
       "<span style=\"color: #60C6C8\">  9: </span><strong>('NVIDIA', 'sentiment-discovery')</strong>\n",
       "<span style=\"color: #208FFB\">...</span>\n",
       "Total <span style=\"color: #208FFB\">665</span> item(s)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_dataset.get_awesome_pytorch_readme()\n",
    "repos = create_dataset.get_repos_from_readme('pytorch_awesome.md')\n",
    "inspect(repos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GUDE_6Ge90Lm"
   },
   "source": [
    "Download zip files. For demonstration we only use 10 repos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "sL0AOQZovkCU",
    "outputId": "0e2282ac-8ed7-4b11-d056-398e38dd2821"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"overflow-x: scroll;\">Download 10 repos...\n",
       "  000:  pytorch/text<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t1,565.99ms</span><strong>\t6,096KB</strong>\n",
       "  Extract pytorch_text<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t131.33ms</span>\n",
       "  001:  IBM/pytorch-seq2seq<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t637.88ms</span><strong>\t1,600KB</strong>\n",
       "  Extract IBM_pytorch-seq2seq<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t44.05ms</span>\n",
       "  002:  Sandeep42/anuvada<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t6,650.76ms</span><strong>\t54,064KB</strong>\n",
       "  Extract Sandeep42_anuvada<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t689.17ms</span>\n",
       "  003:  pytorch/audio<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t746.61ms</span><strong>\t3,480KB</strong>\n",
       "  Extract pytorch_audio<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t78.85ms</span>\n",
       "  004:  facebookresearch/loop<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t616.39ms</span><strong>\t135KB</strong>\n",
       "  Extract facebookresearch_loop<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t8.87ms</span>\n",
       "  005:  facebookresearch/fairseq-py<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t707.66ms</span><strong>\t3,475KB</strong>\n",
       "  Extract facebookresearch_fairseq-py<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t120.18ms</span>\n",
       "  006:  awni/speech<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t535.16ms</span><strong>\t111KB</strong>\n",
       "  Extract awni_speech<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t12.23ms</span>\n",
       "  007:  OpenNMT/OpenNMT-py<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t5,232.76ms</span><strong>\t79,624KB</strong>\n",
       "  Extract OpenNMT_OpenNMT-py<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t785.23ms</span>\n",
       "  008:  huggingface/neuralcoref<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t4,151.69ms</span><strong>\t68,382KB</strong>\n",
       "  Extract huggingface_neuralcoref<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t746.99ms</span>\n",
       "  009:  NVIDIA/sentiment-discovery<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t10,138.96ms</span><strong>\t55,457KB</strong>\n",
       "  Extract NVIDIA_sentiment-discovery<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t1,200.77ms</span>\n",
       "Download 10 repos<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t34,964.14ms</span>\n",
       "</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "repos = repos[:10]\n",
    "for i, r in monit.enum(f\"Download {len(repos)} repos\", repos):\n",
    "    #  Download the repository zip\n",
    "    zip_file = create_dataset.download_repo(r[0], r[1], i)\n",
    "    # Extract the zip file\n",
    "    extracted = create_dataset.extract_zip(zip_file)\n",
    "    # Remove non .py files\n",
    "    create_dataset.remove_files(extracted, {'.py'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZvKx4rWpQZS"
   },
   "source": [
    "Get list of python files across all repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "FqVq3acy4LYg",
    "outputId": "fa45eccd-ca8a-449a-c4a7-ee1492ca8b64"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"overflow-x: scroll;\"><span style=\"color: #60C6C8\">   0: </span><strong>PythonFile(relative_path='build_tools/setup_helpers/extension.py', project='pyto</strong><span style=\"color: #DDB62B\"> ...</span>\n",
       "<span style=\"color: #60C6C8\">   1: </span><strong>PythonFile(relative_path='fairseq/models/fairseq_model.py', project='facebookres</strong><span style=\"color: #DDB62B\"> ...</span>\n",
       "<span style=\"color: #60C6C8\">   2: </span><strong>PythonFile(relative_path='test/data/test_pipeline.py', project='pytorch_text', p</strong><span style=\"color: #DDB62B\"> ...</span>\n",
       "<span style=\"color: #60C6C8\">   3: </span><strong>PythonFile(relative_path='fairseq/modules/quantization/pq/pq.py', project='faceb</strong><span style=\"color: #DDB62B\"> ...</span>\n",
       "<span style=\"color: #60C6C8\">   4: </span><strong>PythonFile(relative_path='docs/source/conf.py', project='OpenNMT_OpenNMT-py', pa</strong><span style=\"color: #DDB62B\"> ...</span>\n",
       "<span style=\"color: #60C6C8\">   5: </span><strong>PythonFile(relative_path='onmt/translate/penalties.py', project='OpenNMT_OpenNMT</strong><span style=\"color: #DDB62B\"> ...</span>\n",
       "<span style=\"color: #60C6C8\">   6: </span><strong>PythonFile(relative_path='test/test_utils.py', project='pytorch_text', path=Posi</strong><span style=\"color: #DDB62B\"> ...</span>\n",
       "<span style=\"color: #60C6C8\">   7: </span><strong>PythonFile(relative_path='onmt/tests/utils_for_tests.py', project='OpenNMT_OpenN</strong><span style=\"color: #DDB62B\"> ...</span>\n",
       "<span style=\"color: #60C6C8\">   8: </span><strong>PythonFile(relative_path='test/data/test_field.py', project='pytorch_text', path</strong><span style=\"color: #DDB62B\"> ...</span>\n",
       "<span style=\"color: #60C6C8\">   9: </span><strong>PythonFile(relative_path='learning_rates.py', project='NVIDIA_sentiment-discover</strong><span style=\"color: #DDB62B\"> ...</span>\n",
       "<span style=\"color: #208FFB\">...</span>\n",
       "Total <span style=\"color: #208FFB\">1027</span> item(s)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "source_files = create_dataset.get_python_files()\n",
    "np.random.shuffle(source_files)\n",
    "inspect(source_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Hs2BSfBpQZS"
   },
   "source": [
    "Split the files into training and validation and merge them into `train.py` and `valid.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "AURmsHE24XbX",
    "outputId": "e251dbd5-0819-4827-f701-306fe7292fe3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"overflow-x: scroll;\">Write train.py<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t901.34ms</span>\n",
       "Write valid.py<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t346.75ms</span>\n",
       "</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_valid_split = int(len(source_files) * 0.9)\n",
    "create_dataset.concat_and_save(lab.get_data_path() / 'train.py', source_files[:train_valid_split])\n",
    "create_dataset.concat_and_save(lab.get_data_path() / 'valid.py', source_files[train_valid_split:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cwK9AzEBpQZT"
   },
   "source": [
    "## Train the model\n",
    "\n",
    "Training script is defined in [`train.py`](https://github.com/lab-ml/python_autocomplete/blob/master/python_autocomplete/train.py).\n",
    "We import the `Configs` class from it and create a new experiment with\n",
    "custom configurations.\n",
    "You can experiment with changing these configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "qFGGXj7H33sX"
   },
   "outputs": [],
   "source": [
    "from python_autocomplete.train import Configs\n",
    "from labml import experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q4hp3V8_pQZT"
   },
   "source": [
    "Initialize `Configs` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "D4vMS55SQkFd"
   },
   "outputs": [],
   "source": [
    "conf = Configs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3C7DteUApQZU"
   },
   "source": [
    "Create a new experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "DaN3E6FDpQZU"
   },
   "outputs": [],
   "source": [
    "experiment.create(name=\"python_autocomplete\",\n",
    "                  comment='Colab demo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x0NV9wo4Q6mb"
   },
   "source": [
    "Set configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "heRVrikNpQZU"
   },
   "source": [
    "A dictionary for custom configurations. You can see the options available for configurations from these configurations of a [previous training I ran](https://web.lab-ml.com/configs?uuid=39b03a1e454011ebbaff2b26e3148b3d)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "lUbEKHlNpQZU"
   },
   "outputs": [],
   "source": [
    "custom_conf = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NS5GxKh1pQZU"
   },
   "source": [
    "We will try a `transformer_model`, you can use `lstm_model` if you want to try a LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "DpF8Hkh-pQZV"
   },
   "outputs": [],
   "source": [
    "custom_conf['model'] = 'transformer_model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zo8PaPplpQZV"
   },
   "source": [
    "Number of layers for the model, we set `2` for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "LY3iVQmlpQZV"
   },
   "outputs": [],
   "source": [
    "custom_conf['n_layers'] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P-n1mo3GpQZV"
   },
   "source": [
    "Batch size for training, you will have to reduce this if you use a larger model due to GPU memory constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "X02w3NyGpQZV"
   },
   "outputs": [],
   "source": [
    "custom_conf['batch_size'] = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d6jP-GM3pQZV"
   },
   "source": [
    "Number of epochs. I usually set a high number on stop the training when the validation loss stops improving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "rp_CUAkxpQZV"
   },
   "outputs": [],
   "source": [
    "custom_conf['epochs'] = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "el64nkB4pQZW"
   },
   "source": [
    "We use [Noam optimizer](https://lab-ml.com/labml_nn/optimizers/noam.html) (one used in original Transformers paper). You can also use something like `AdamW` (Adam with warmup). Transformer training usually needs a warmup session where the learning rate is kept low during initial training steps. \n",
    "\n",
    "Note that the learning rate is `1.0`, the actual learning rate will be $<10^{-3}$ because [Noam optimizer](https://lab-ml.com/labml_nn/optimizers/noam.html) factors the learning rate by $\\frac{1}{\\sqrt{d_{model}}}$ where $d_{model}$ is the number of dimensions in the transformer feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "51TPVQD5pQZW"
   },
   "outputs": [],
   "source": [
    "custom_conf['optimizer.optimizer'] = 'Noam'\n",
    "custom_conf['optimizer.learning_rate'] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SVqr939VpQZW"
   },
   "source": [
    "Number of characters in a sample. This defaults to `512`, but we specify it here to make it easier to change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "JcvNf_URpQZW"
   },
   "outputs": [],
   "source": [
    "custom_conf['seq_len'] = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2PIQllI3pQZW"
   },
   "source": [
    "Our training switches between training and validation within an epoch, so that we get a the validation loss (for a fraction of vlaidation data) more frequently. This is especially useful when an epoch take a lot longer to train. `inner_iterations` should be increased depending on how large the training dataset is (hence longer time per epoch). We set it at 5 since we are only training on $10$ repositories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "8QWN3RDFpQZW"
   },
   "outputs": [],
   "source": [
    "custom_conf['inner_iterations'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "EsV-pjvo6hbq",
    "outputId": "53c64523-c7f5-4350-ddfd-a55c7d79cf33"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"overflow-x: scroll;\"></pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment.configs(conf, custom_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDB3DLNEpQZX"
   },
   "source": [
    "Add models for saving and loading. If you plan to stop and continue the training you should include the optimizer also for saving.\n",
    "\n",
    "*Accessing `conf.model` loads the model and the dataset to calculate the number of tokens (specific characters) (needed to initialize the model)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "JU-DcoCr39f3",
    "outputId": "a379f591-ef5b-4c98-8c81-3f6ef55994a6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"overflow-x: scroll;\">Prepare model...\n",
       "  Prepare n_tokens...\n",
       "    Prepare text...\n",
       "      Prepare tokenizer<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t3.03ms</span>\n",
       "      Load data<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t8.32ms</span>\n",
       "      Tokenize<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t152.60ms</span>\n",
       "      Build vocabulary<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t157.12ms</span>\n",
       "    Prepare text<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t332.70ms</span>\n",
       "  Prepare n_tokens<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t337.82ms</span>\n",
       "  Prepare transformer<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t2.97ms</span>\n",
       "  Prepare encoder...\n",
       "    Prepare encoder_layer...\n",
       "      Prepare encoder_attn<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t73.50ms</span>\n",
       "      Prepare feed_forward<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t33.57ms</span>\n",
       "    Prepare encoder_layer<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t127.87ms</span>\n",
       "  Prepare encoder<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t140.82ms</span>\n",
       "  Prepare src_embed<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t105.84ms</span>\n",
       "  Prepare device...\n",
       "    Prepare device_info<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t57.67ms</span>\n",
       "  Prepare device<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t64.60ms</span>\n",
       "Prepare model<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t10,906.87ms</span>\n",
       "</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment.add_pytorch_models({'model': conf.model})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y2sTVpvLpQZX"
   },
   "source": [
    "Start the experiment and run it. You can optionally load and continue from a previously saved run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "id": "9C_nSTOnQveY",
    "outputId": "ead5ff05-3c1a-4be8-f575-4aabc92aaf5e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"overflow-x: scroll;\">\n",
       "<strong><span style=\"text-decoration: underline\">python_autocomplete</span></strong>: <span style=\"color: #208FFB\">26f84ce64e4511eb8d230242ac1c0002</span>\n",
       "\t<strong><span style=\"color: #DDB62B\">Colab demo</span></strong>\n",
       "\t[dirty]: <strong><span style=\"color: #DDB62B\">\"\"</span></strong>\n",
       "Initialize...\n",
       "  Prepare mode<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t5.62ms</span>\n",
       "Initialize<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t84.36ms</span>\n",
       "Prepare validator...\n",
       "  Prepare valid_loader<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t140.73ms</span>\n",
       "Prepare validator<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t255.78ms</span>\n",
       "<span style=\"color: #C5C1B4\"></span>\n",
       "<span style=\"color: #C5C1B4\">--------------------------------------------------</span><span style=\"color: #DDB62B\"><strong><span style=\"text-decoration: underline\"></span></strong></span>\n",
       "<span style=\"color: #DDB62B\"><strong><span style=\"text-decoration: underline\">LABML WARNING</span></strong></span>\n",
       "<span style=\"color: #DDB62B\"><strong><span style=\"text-decoration: underline\"></span></strong></span>LabML App Warning: <span style=\"color: #60C6C8\">empty_token: </span><strong>Please create a valid token at https://web.lab-ml.com.</strong>\n",
       "<strong>Click on the experiment link to monitor the experiment and add it to your experiments list.</strong><span style=\"color: #C5C1B4\"></span>\n",
       "<span style=\"color: #C5C1B4\">--------------------------------------------------</span>\n",
       "<span style=\"color: #208FFB\">Monitor experiment at </span><a href='https://web.lab-ml.com/run?uuid=26f84ce64e4511eb8d230242ac1c0002' target='blank'>https://web.lab-ml.com/run?uuid=26f84ce64e4511eb8d230242ac1c0002</a>\n",
       "Prepare trainer...\n",
       "  Prepare train_loader<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t557.35ms</span>\n",
       "Prepare trainer<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t603.53ms</span>\n",
       "Prepare training_loop...\n",
       "  Prepare loop_count<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t45.26ms</span>\n",
       "Prepare training_loop<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t310.10ms</span>\n",
       "<span style=\"color: #C5C1B4\">def train(</span><strong>P</strong><strong>I</strong><strong>6</strong><strong>F</strong><strong>\t</strong><strong>~</strong><strong>u</strong><strong>^</strong><strong>S</strong><strong>q</strong><strong>\t</strong><strong>~</strong><strong>u</strong><strong>^</strong><strong>S</strong><strong>q</strong><strong>\t</strong><strong>~</strong><strong>u</strong><strong>^</strong><strong>S</strong><strong>q</strong><strong>\t</strong><strong>~</strong><strong>u</strong>\n",
       "<span style=\"color: #C5C1B4\">def train(</span><strong>P</strong><strong>I</strong><strong>6</strong><strong>F</strong><strong>\t</strong><strong>~</strong><strong>u</strong><strong>^</strong><strong>n</strong><strong>v</strong><strong>v</strong><strong>v</strong><strong>v</strong><strong>v</strong><strong>v</strong><strong>v</strong><strong>v</strong><strong>v</strong><strong>v</strong><strong>v</strong><strong>v</strong><strong>v</strong><strong>v</strong><strong>v</strong><strong>v</strong>\n",
       "<span style=\"color: #C5C1B4\">def train(</span><strong>P</strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong>\n",
       "<span style=\"color: #C5C1B4\">def train(</span><strong>m</strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong>\n",
       "<span style=\"color: #C5C1B4\">def train(</span><strong>s</strong><strong>e</strong><strong>r</strong><strong>e</strong><strong>r</strong><strong>e</strong><strong>r</strong><strong>e</strong><strong>r</strong><strong>e</strong><strong>r</strong><strong>e</strong><strong>r</strong><strong>e</strong><strong>r</strong><strong>e</strong><strong>r</strong><strong>e</strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong>\n",
       "<strong><span style=\"color: #DDB62B\">  87,552:  </span></strong>Sample:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">   170ms  </span>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 237,202ms  </span>Valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 7,686ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 2.75855</span> loss.valid: <span style=\"color: #C5C1B4\"> 3.47120</span> accuracy.train: <span style=\"color: #C5C1B4\">0.196427</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.226050</span>  <span style=\"color: #208FFB\">237,872ms</span><span style=\"color: #D160C4\">  0:03m/  2:02m  </span>\n",
       "<span style=\"color: #C5C1B4\">def train(</span><strong>s</strong><strong>e</strong><strong>l</strong><strong>e</strong><strong>r</strong><strong>e</strong><strong>r</strong><strong>e</strong><strong>r</strong><strong>e</strong><strong>r</strong><strong>e</strong><strong>r</strong><strong>e</strong><strong>r</strong><strong>e</strong><strong>r</strong><strong>e</strong><strong>n</strong><strong>s</strong><strong>e</strong><strong>r</strong><strong>e</strong><strong>n</strong><strong>s</strong>\n",
       "<span style=\"color: #C5C1B4\">def train(</span><strong>s</strong><strong>e</strong><strong>n</strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong>\n",
       "<span style=\"color: #C5C1B4\">def train(</span><strong>s</strong><strong>e</strong><strong>n</strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong>\n",
       "<span style=\"color: #C5C1B4\">def train(</span><strong>s</strong><strong>e</strong><strong>n</strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong>\n",
       "<strong><span style=\"color: #DDB62B\"> 141,824:  </span></strong>Sample:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">   165ms  </span>Train:<span style=\"color: #C5C1B4\">  61%</span><span style=\"color: #208FFB\"> 264,115ms  </span>Valid:<span style=\"color: #C5C1B4\">  57%</span><span style=\"color: #208FFB\"> 8,049ms  </span> loss.train: <strong> 2.53339</strong> loss.valid: <span style=\"color: #C5C1B4\"> 2.70110</span> accuracy.train: <span style=\"color: #C5C1B4\">0.196427</span> accuracy.valid: <span style=\"color: #C5C1B4\">0.226050</span>  <span style=\"color: #208FFB\">237,872ms</span><span style=\"color: #D160C4\">  0:06m/  2:00m  </span></pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# experiment.load('d5ba7f56d88911eaa6629b54a83956dc')\n",
    "with experiment.start():\n",
    "    conf.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PUJL3TYxQzro"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "labml autocomplete",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
